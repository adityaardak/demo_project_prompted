{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "855df2f4",
   "metadata": {},
   "source": [
    "# Data Cleaning & Preprocessing (Classification Competition)\n",
    "This notebook performs **competition-grade data cleaning** and exports a cleaned dataset that will be reused in later notebooks.\n",
    "\n",
    "✅ Outputs:\n",
    "- `data/cleaned_students.csv` (cleaned features + target class)\n",
    "- `data/cleaning_report.json` (quick summary for reproducibility)\n",
    "\n",
    "Target for classification will be created from `exam_score` as `exam_score_class`.\n",
    "- **Low**: < 50\n",
    "- **Medium**: 50 to 75 (inclusive)\n",
    "- **High**: > 75\n",
    "\n",
    "> You can change thresholds in the `TARGET_BINNING` cell if your competition uses different labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427f8557",
   "metadata": {},
   "source": [
    "## 0) Setup\n",
    "This section imports libraries and sets notebook-wide options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a02ecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Display options\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "pd.set_option(\"display.max_rows\", 80)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(\"✅ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ffd6e3",
   "metadata": {},
   "source": [
    "## 1) Load Data\n",
    "Update `DATA_PATH` if your dataset file name/location is different.\n",
    "\n",
    "**Recommended folder structure**:\n",
    "- `data/raw_students.csv` (input)\n",
    "- `data/cleaned_students.csv` (output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363a680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Update this path if needed ===\n",
    "DATA_PATH = Path(\"data/raw_students.csv\")\n",
    "\n",
    "# Output paths\n",
    "OUT_DIR = Path(\"data\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CLEAN_PATH = OUT_DIR / \"cleaned_students.csv\"\n",
    "REPORT_PATH = OUT_DIR / \"cleaning_report.json\"\n",
    "\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"❌ Could not find file at: {DATA_PATH}\\n\"\n",
    "        f\"➡️ Place your dataset there OR update DATA_PATH accordingly.\"\n",
    "    )\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"✅ Loaded:\", DATA_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04fb635",
   "metadata": {},
   "source": [
    "## 2) Quick Audit\n",
    "We check columns, dtypes, missing values, duplicates, and basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec281f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns:\", list(df.columns))\n",
    "display(df.info())\n",
    "\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "display(pd.DataFrame({\"missing\": missing, \"missing_%\": (missing/len(df)*100).round(3)}).head(20))\n",
    "\n",
    "dup_count = df.duplicated().sum()\n",
    "print(\"Duplicate rows:\", dup_count)\n",
    "\n",
    "display(df.describe(include=\"all\").T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edd23fe",
   "metadata": {},
   "source": [
    "## 3) Standardize Column Names (safe)\n",
    "We keep your original column names if already clean, but we also ensure no accidental spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0820d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "# Expected columns based on your sample description\n",
    "EXPECTED_COLS = [\n",
    "    \"student_id\", \"age\", \"gender\", \"course\", \"study_hours\", \"class_attendance\",\n",
    "    \"internet_access\", \"sleep_hours\", \"sleep_quality\", \"study_method\",\n",
    "    \"facility_rating\", \"exam_difficulty\", \"exam_score\"\n",
    "]\n",
    "\n",
    "missing_cols = [c for c in EXPECTED_COLS if c not in df.columns]\n",
    "extra_cols = [c for c in df.columns if c not in EXPECTED_COLS]\n",
    "\n",
    "print(\"Missing expected columns:\", missing_cols)\n",
    "print(\"Extra columns (allowed):\", extra_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45f787b",
   "metadata": {},
   "source": [
    "## 4) Fix Categorical Text (lowercase, strip)\n",
    "This avoids accidental duplicates like `'Male'` vs `'male '`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002b8dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "print(\"Categorical cols detected:\", cat_cols)\n",
    "\n",
    "def normalize_text(s: pd.Series) -> pd.Series:\n",
    "    return (s.astype(str)\n",
    "            .str.strip()\n",
    "            .str.lower()\n",
    "            .replace({\"nan\": np.nan, \"none\": np.nan, \"\": np.nan})\n",
    "           )\n",
    "\n",
    "for c in cat_cols:\n",
    "    df[c] = normalize_text(df[c])\n",
    "\n",
    "# Optional: show unique values (top)\n",
    "for c in cat_cols:\n",
    "    uniques = df[c].dropna().unique()\n",
    "    print(f\"\\n{c} uniques ({len(uniques)}): {uniques[:30]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2552d7c",
   "metadata": {},
   "source": [
    "## 5) Validate & Repair Numeric Ranges\n",
    "Competition-friendly cleaning: we **cap** outliers rather than dropping many rows.\n",
    "\n",
    "We apply sensible domain constraints:\n",
    "- `age`: 15–30 (sample indicates 17–24)\n",
    "- `study_hours`: 0–16 (sample indicates ~0–8)\n",
    "- `class_attendance`: 0–100\n",
    "- `sleep_hours`: 0–24 (sample indicates ~4–10)\n",
    "- `exam_score`: 0–100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa2d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include=[\"int64\", \"float64\", \"int32\", \"float32\"]).columns.tolist()\n",
    "print(\"Numeric cols detected:\", num_cols)\n",
    "\n",
    "RANGES = {\n",
    "    \"age\": (15, 30),\n",
    "    \"study_hours\": (0, 16),\n",
    "    \"class_attendance\": (0, 100),\n",
    "    \"sleep_hours\": (0, 24),\n",
    "    \"exam_score\": (0, 100),\n",
    "}\n",
    "\n",
    "range_report = {}\n",
    "for col, (lo, hi) in RANGES.items():\n",
    "    if col not in df.columns:\n",
    "        continue\n",
    "    before_invalid = ((df[col] < lo) | (df[col] > hi)).sum()\n",
    "    df[col] = df[col].clip(lo, hi)\n",
    "    after_invalid = ((df[col] < lo) | (df[col] > hi)).sum()\n",
    "    range_report[col] = {\"clipped_before\": int(before_invalid), \"clipped_after\": int(after_invalid)}\n",
    "\n",
    "pd.DataFrame(range_report).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89828d1",
   "metadata": {},
   "source": [
    "## 6) Handle Missing Values\n",
    "Your sample suggests there are no missing values, but competitions can include them.\n",
    "\n",
    "- Numeric: fill with median\n",
    "- Categorical: fill with mode (`most frequent`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da96932",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_before = df.isna().sum().sum()\n",
    "print(\"Total missing values (before):\", int(missing_before))\n",
    "\n",
    "# Identify columns by type\n",
    "cat_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = [c for c in df.columns if c not in cat_cols]\n",
    "\n",
    "# Fill numeric\n",
    "for c in num_cols:\n",
    "    if df[c].isna().any():\n",
    "        df[c] = df[c].fillna(df[c].median())\n",
    "\n",
    "# Fill categorical\n",
    "for c in cat_cols:\n",
    "    if df[c].isna().any():\n",
    "        mode = df[c].mode(dropna=True)\n",
    "        fill_val = mode.iloc[0] if len(mode) else \"unknown\"\n",
    "        df[c] = df[c].fillna(fill_val)\n",
    "\n",
    "missing_after = df.isna().sum().sum()\n",
    "print(\"Total missing values (after):\", int(missing_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a192796",
   "metadata": {},
   "source": [
    "## 7) Remove Duplicates (if any)\n",
    "We drop exact duplicates. `student_id` duplicates are handled separately if present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd51a8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_rows = df.duplicated().sum()\n",
    "print(\"Exact duplicate rows:\", int(dup_rows))\n",
    "\n",
    "if dup_rows > 0:\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(\"Shape after dropping exact duplicates:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e7f407",
   "metadata": {},
   "source": [
    "## 8) Student ID Sanity\n",
    "`student_id` is an identifier and will be excluded from modeling later, but we keep it here.\n",
    "If duplicates exist, we keep the first occurrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837b025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"student_id\" in df.columns:\n",
    "    dup_id = df[\"student_id\"].duplicated().sum()\n",
    "    print(\"Duplicate student_id count:\", int(dup_id))\n",
    "    if dup_id > 0:\n",
    "        df = df.drop_duplicates(subset=[\"student_id\"]).reset_index(drop=True)\n",
    "        print(\"✅ Dropped duplicate student_id rows. New shape:\", df.shape)\n",
    "else:\n",
    "    print(\"⚠️ student_id column not found (ok if your dataset differs).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d494df42",
   "metadata": {},
   "source": [
    "## 9) Create Classification Target (`exam_score_class`)\n",
    "Since the project is for **classification**, we convert numeric `exam_score` into discrete classes.\n",
    "\n",
    "Default bins:\n",
    "- Low: `< 50`\n",
    "- Medium: `50–75`\n",
    "- High: `> 75`\n",
    "\n",
    "If your competition provides specific class labels, update the thresholds here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3de7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Adjust thresholds here if needed ===\n",
    "LOW_MAX = 50\n",
    "HIGH_MIN = 75\n",
    "\n",
    "if \"exam_score\" not in df.columns:\n",
    "    raise ValueError(\"❌ 'exam_score' column not found. Please verify your dataset columns.\")\n",
    "\n",
    "def score_to_class(x: float) -> str:\n",
    "    if x < LOW_MAX:\n",
    "        return \"low\"\n",
    "    elif x <= HIGH_MIN:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"high\"\n",
    "\n",
    "df[\"exam_score_class\"] = df[\"exam_score\"].apply(score_to_class)\n",
    "\n",
    "# Distribution\n",
    "dist = df[\"exam_score_class\"].value_counts()\n",
    "dist_pct = (dist / len(df) * 100).round(2)\n",
    "display(pd.DataFrame({\"count\": dist, \"percent\": dist_pct}))\n",
    "\n",
    "df[[\"exam_score\", \"exam_score_class\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6ff7f5",
   "metadata": {},
   "source": [
    "## 10) Final Type Checks + Export\n",
    "We export the cleaned dataset for downstream steps.\n",
    "\n",
    "Saved file will be used in:\n",
    "- `eda.ipynb`\n",
    "- `feature_engineering.ipynb`\n",
    "- `model.ipynb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78ecf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: enforce expected dtypes (safe casting)\n",
    "# Note: We do not cast aggressively if columns are missing.\n",
    "dtype_plan = {\n",
    "    \"student_id\": \"int64\",\n",
    "    \"age\": \"int64\",\n",
    "    \"study_hours\": \"float64\",\n",
    "    \"class_attendance\": \"float64\",\n",
    "    \"sleep_hours\": \"float64\",\n",
    "    \"exam_score\": \"float64\",\n",
    "}\n",
    "\n",
    "for col, dt in dtype_plan.items():\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(dt)\n",
    "\n",
    "# final missing check\n",
    "assert df.isna().sum().sum() == 0, \"❌ Missing values still present after cleaning.\"\n",
    "\n",
    "# Save cleaned dataset\n",
    "df.to_csv(CLEAN_PATH, index=False)\n",
    "print(\"✅ Cleaned dataset saved to:\", CLEAN_PATH)\n",
    "\n",
    "# Save quick report\n",
    "report = {\n",
    "    \"input_path\": str(DATA_PATH),\n",
    "    \"output_path\": str(CLEAN_PATH),\n",
    "    \"rows\": int(df.shape[0]),\n",
    "    \"cols\": int(df.shape[1]),\n",
    "    \"duplicate_rows_removed\": int(dup_rows),\n",
    "    \"range_clipping\": range_report,\n",
    "    \"target_binning\": {\"low_max_exclusive\": LOW_MAX, \"high_min_inclusive\": HIGH_MIN},\n",
    "    \"target_distribution\": df[\"exam_score_class\"].value_counts().to_dict(),\n",
    "    \"columns\": list(df.columns),\n",
    "}\n",
    "\n",
    "with open(REPORT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(\"✅ Cleaning report saved to:\", REPORT_PATH)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906ab8d6",
   "metadata": {},
   "source": [
    "## 11) Quick Smoke Tests\n",
    "These checks ensure the exported dataset is stable for later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d8a378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload to verify\n",
    "df_check = pd.read_csv(CLEAN_PATH)\n",
    "\n",
    "print(\"Reloaded shape:\", df_check.shape)\n",
    "print(\"Target classes:\", df_check[\"exam_score_class\"].unique())\n",
    "\n",
    "# Basic sanity\n",
    "assert set(df_check[\"exam_score_class\"].unique()).issubset({\"low\", \"medium\", \"high\"})\n",
    "assert df_check[\"exam_score\"].between(0, 100).all()\n",
    "\n",
    "print(\"✅ Smoke tests passed\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}